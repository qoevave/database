"use strict";(self.webpackChunkdatabase=self.webpackChunkdatabase||[]).push([[73],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>d});var i=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,i)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,i,n=function(e,t){if(null==e)return{};var a,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)a=o[i],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var l=i.createContext({}),c=function(e){var t=i.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},u=function(e){var t=c(e.components);return i.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},p=i.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),p=c(a),d=n,h=p["".concat(l,".").concat(d)]||p[d]||m[d]||o;return a?i.createElement(h,r(r({ref:t},u),{},{components:a})):i.createElement(h,r({ref:t},u))}));function d(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,r=new Array(o);r[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:n,r[1]=s;for(var c=2;c<o;c++)r[c]=a[c];return i.createElement.apply(null,r)}return i.createElement.apply(null,a)}p.displayName="MDXCreateElement"},4858:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>g,contentTitle:()=>h,default:()=>b,frontMatter:()=>d,metadata:()=>f,toc:()=>v});var i=a(7462),n=a(7294),o=a(3905);const r={profileContainer:"profileContainer__Z64",avatar:"avatar_nPfx",userTitleText:"userTitleText_TaXw",positionText:"positionText_EOL_"},s=[{name:"Thomas Robotham",imageUrl:"https://www.audiolabs-erlangen.de/media/pages/fau/assistant/robotham/7af68c64d7-1616922882/dsc07789-7-portrait-200x.jpg",imageSize:80,position:"Respository Maintainer - PhD Student"},{name:"Emanu\xebl A. P. Habets",imageUrl:"https://scholar.googleusercontent.com/citations?view_op=view_photo&user=2Za2MMIAAAAJ&citpid=7",imageSize:80,position:"Principle Investigator"}];function l(){return n.createElement("div",null,s.map(((e,t)=>n.createElement("div",{key:t,className:r.profileContainer},n.createElement("img",{className:r.avatar,src:e.imageUrl,alt:"Photo of "+e.name}),n.createElement("div",{className:r.profileText},n.createElement("h2",{className:r.userTitleText},e.name),n.createElement("p",{className:r.positionText},e.position))))))}const c=[{name:"William Menz",imageUrl:"https://www.tu-ilmenau.de/fileadmin/Bereiche/EI/mt-avt/photos/team/Menz-William_2022.jpg",imageSize:80,position:"PhD Student"},{name:"Alexander Raake",imageUrl:"https://scholar.googleusercontent.com/citations?view_op=view_photo&user=MoOhyrQAAAAJ&citpid=5",imageSize:80,position:"Principle Investigator"}];function u(){return n.createElement("div",null,c.map(((e,t)=>n.createElement("div",{key:t,className:r.profileContainer},n.createElement("img",{className:r.avatar,src:e.imageUrl,alt:"Photo of "+e.name}),n.createElement("div",{className:r.profileText},n.createElement("h2",{className:r.userTitleText},e.name),n.createElement("p",{className:r.positionText},e.position))))))}const m=[{name:"Olli S. Rummukainen",imageUrl:"https://scholar.googleusercontent.com/citations?view_op=view_photo&user=-76G_nAAAAAJ&citpid=1",imageSize:80,position:"Associated Reseacher. AudioLabs (- April 2021)"},{name:"Ashutosh Singla",imageUrl:"https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fwww.spp2236-audictive.de%2Fimages%2Fsingla2.jpg&f=1&nofb=1&ipt=3e11e2c72b179246e9323fc870578bdc1ffeea406c4f8691c1d9d30a97643523&ipo=images",imageSize:80,position:"PhD Student. AVT (- 2022)"}];function p(){return n.createElement("div",null,m.map(((e,t)=>n.createElement("div",{key:t,className:r.profileContainer},n.createElement("img",{className:r.avatar,src:e.imageUrl,alt:"Photo of "+e.name}),n.createElement("div",{className:r.profileText},n.createElement("h2",{className:r.userTitleText},e.name),n.createElement("p",{className:r.positionText},e.position))))))}const d={sidebar_position:4,custom_edit_url:null},h="About The Project",f={unversionedId:"about",id:"about",title:"About The Project",description:"QoEVAVE",source:"@site/docs/about.mdx",sourceDirName:".",slug:"/about",permalink:"/database/docs/about",draft:!1,editUrl:null,tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4,custom_edit_url:null},sidebar:"docs",previous:{title:"Available Databases",permalink:"/database/docs/intro"},next:{title:"Scene Database",permalink:"/database/docs/Scenes/"}},g={},v=[{value:"QoEVAVE",id:"qoevave",level:2},{value:"Project Partners",id:"project-partners",level:2},{value:"International Audio Laboratories Erlangen*",id:"international-audio-laboratories-erlangen",level:3},{value:"Team",id:"team",level:4},{value:"Audiovisual Technology Group, Technische Universit\xe4t Ilmenau",id:"audiovisual-technology-group-technische-universit\xe4t-ilmenau",level:3},{value:"Team",id:"team-1",level:4},{value:"Alumni",id:"alumni",level:3},{value:"Funding",id:"funding",level:2}],y={toc:v};function b(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,i.Z)({},y,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"about-the-project"},"About The Project"),(0,o.kt)("h2",{id:"qoevave"},"QoEVAVE"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"Quality of Experience Evaluation of Interactive Virtual Environments with Audiovisual Scenes")),(0,o.kt)("p",null,"Interactive virtual environments (IVEs) aim to replace real-world sensory input with corresponding streams of artificial stimulation. If successful, such a replacement will make the technology transparent and allow the user to interact naturally in a virtual world. Hence, how close to real life the IVE experience can get represents a key criterion for IVE quality. IVEs bring new challenges to quality evaluation and render current evaluation approaches in the audio and video communities partially inapplicable. Traditionally, the quality judgment is a dedicated cognitive process, and the participant is constantly aware of the quality judgment task. In contrast, IVEs rely on presence through immersion. Introducing a quality judgment task may reduce immersion in the IVE experience, which in turn affects the quality."),(0,o.kt)("p",null,"The QoEVAVE project draws inspiration from the virtual reality (VR) community and the long history of using indirect methods to investigate cognitive functions of immersion, presence, and performance in IVEs. The project aims at finding and closing the gaps in current quality evaluation methodologies for audio and video, and examines the feasibility of inferring quality from human behavior in an IVE. IVEs are multimodal and allow 3- or 6-degrees-of-freedom movement in the virtual scene. Compared to a uni-modal scenario, state-of-the-art research shows that multimodal sensory stimulation has significant effects on the resulting object localization, attention and quality evaluation, to name a few perceptual aspects. Regardless, quality evaluation today is mostly conducted within a specific sensory modality and without interaction. QoEVAVE builds upon the foundation of quality of experience (QoE) research and integrates methodologies from the VR community to develop the first QoE framework for IVEs. Here, the aim is to achieve an integrated view of IVE quality perception as a cognitive process and of cognitive performances on specific tasks as IVE-quality indicators."),(0,o.kt)("p",null,"The QoEVAVE project addresses the three Audictive priorities. Its main emphasis is on the quality evaluation priority area (C), developing a taxonomy and framework of IVE-quality evaluation methods. Next, the project addresses the auditory cognition priority area (A), since it aims to expand classical QoE-evaluation approaches by systematically including aspects of auditory and audiovisual cognition and hence task-performance into the assessment schemes. Finally, it addresses the IVEs priority area (B) by investigating QoE and cognitive performance in multiple instances of IVEs. The project builds upon state-of-the-art technologies of audiovisual IVEs and explores the possibilities for advancing audio rendering in virtual environments. In summary, the project recognizes the divergence between the VR community and the media technology community and sets its aim to unifying the field with regards to QoE evaluation in IVEs."),(0,o.kt)("admonition",{type:"info"},(0,o.kt)("p",{parentName:"admonition"},"More information on the ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("a",{parentName:"strong",href:"http://www.spp2236-audictive.de/index.html"},"Audictive Priority Program"))," website")),(0,o.kt)("h2",{id:"project-partners"},"Project Partners"),(0,o.kt)("h3",{id:"international-audio-laboratories-erlangen"},"International Audio Laboratories Erlangen*"),(0,o.kt)("p",null,"*A joint institution of the Friedrich-Alexander-Universit\xe4t Erlangen-\nN\xfcrnberg (FAU) and Fraunhofer Institute for Integrated Circuits (IIS)."),(0,o.kt)("h4",{id:"team"},"Team"),(0,o.kt)(l,{mdxType:"FAUProfiles"}),(0,o.kt)("h3",{id:"audiovisual-technology-group-technische-universit\xe4t-ilmenau"},"Audiovisual Technology Group, Technische Universit\xe4t Ilmenau"),(0,o.kt)("h4",{id:"team-1"},"Team"),(0,o.kt)(u,{mdxType:"TUILProfiles"}),(0,o.kt)("h3",{id:"alumni"},"Alumni"),(0,o.kt)(p,{mdxType:"AlumniProfiles"}),(0,o.kt)("h2",{id:"funding"},"Funding"),(0,o.kt)("p",null,"This research was funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) project number 444832250 - SPP 2236"))}b.isMDXComponent=!0}}]);